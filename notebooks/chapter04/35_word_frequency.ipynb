{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36f226a",
   "metadata": {},
   "source": [
    "# 問題35: 単語の出現頻度\n",
    "\n",
    "形態素解析結果から単語の出現頻度を求め，出現頻度の高い順に並べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e905203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題30で実装した関数を読み込む\n",
    "import sys\n",
    "sys.path.append('../..')  # 親ディレクトリをパスに追加\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 日本語表示のための設定\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "# 形態素解析結果を読み込む関数\n",
    "def load_mecab_result(file_path):\n",
    "    \"\"\"\n",
    "    MeCabの解析結果ファイルを読み込み、各形態素を辞書のリストとして返す関数\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): MeCab出力ファイルのパス\n",
    "        \n",
    "    Returns:\n",
    "        list: 文のリスト。各文は形態素（辞書）のリスト\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # EOSは文の区切り\n",
    "            if line == 'EOS\\n':\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "                continue\n",
    "                \n",
    "            # 空行をスキップ\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "                \n",
    "            # タブで分割して表層形とそれ以外の情報に分ける\n",
    "            try:\n",
    "                surface, info = line.split('\\t')\n",
    "                \n",
    "                # カンマで分割して品詞情報などを取得\n",
    "                info_items = info.split(',')\n",
    "                \n",
    "                # 形態素情報を辞書として格納\n",
    "                morpheme = {\n",
    "                    'surface': surface,\n",
    "                    'base': info_items[6],\n",
    "                    'pos': info_items[0],\n",
    "                    'pos1': info_items[1]\n",
    "                }\n",
    "                \n",
    "                current_sentence.append(morpheme)\n",
    "            except:\n",
    "                # 不正な形式の行をスキップ\n",
    "                continue\n",
    "    \n",
    "    # 最後の文が追加されていない場合に追加\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# 単語の出現頻度を計算する関数\n",
    "def count_word_frequency(sentences):\n",
    "    \"\"\"\n",
    "    形態素解析結果から単語の出現頻度を計算し、頻度順にソートする関数\n",
    "    \n",
    "    Args:\n",
    "        sentences (list): 文のリスト。各文は形態素（辞書）のリスト\n",
    "        \n",
    "    Returns:\n",
    "        list: (単語, 出現頻度)のタプルのリスト。出現頻度の降順でソート済み\n",
    "    \"\"\"\n",
    "    # 全ての形態素の表層形を抽出\n",
    "    words = [morpheme['surface'] for sentence in sentences for morpheme in sentence]\n",
    "    \n",
    "    # 単語の出現回数をカウント\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # 出現頻度の降順でソート\n",
    "    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e90263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析結果の読み込み\n",
    "file_path = '../../data/neko.txt.mecab'\n",
    "sentences = load_mecab_result(file_path)\n",
    "\n",
    "# 単語の出現頻度を計算\n",
    "word_frequencies = count_word_frequency(sentences)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"異なり語数（ユニークな単語の数）: {len(word_frequencies)}\")\n",
    "print(\"\\n出現頻度上位20語:\")\n",
    "for word, count in word_frequencies[:20]:\n",
    "    print(f\"{word}: {count}回\")\n",
    "\n",
    "# データフレームに変換して表示\n",
    "df = pd.DataFrame(word_frequencies[:20], columns=['単語', '出現頻度'])\n",
    "display(df)\n",
    "\n",
    "# 出現頻度上位20語の棒グラフを作成\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['単語'], df['出現頻度'], color='skyblue')\n",
    "plt.title('出現頻度上位20語')\n",
    "plt.xlabel('単語')\n",
    "plt.ylabel('出現頻度')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1330dc",
   "metadata": {},
   "source": [
    "## 解説\n",
    "\n",
    "この問題では、形態素解析結果から単語の出現頻度を計算し、頻度順にソートしました。\n",
    "\n",
    "### 実装のポイント\n",
    "\n",
    "1. **単語の抽出**: 全ての文から形態素の表層形を抽出しています。\n",
    "\n",
    "2. **頻度のカウント**: Pythonの`collections.Counter`を使用して、効率的に単語の出現回数をカウントしています。\n",
    "\n",
    "3. **ソート**: 出現頻度の降順でソートして、頻出語を上位に表示しています。\n",
    "\n",
    "4. **可視化**: 出現頻度上位の単語を棒グラフで視覚化しています。\n",
    "\n",
    "### 出現頻度の特徴\n",
    "\n",
    "単語の出現頻度分布には、一般的に以下のような特徴があります：\n",
    "\n",
    "1. **少数の高頻度語**: 少数の単語（主に助詞、助動詞などの機能語）が非常に高い頻度で出現します。\n",
    "\n",
    "2. **多数の低頻度語**: 大多数の単語は低い頻度でしか出現しません。多くの単語は1回か2回しか出現しないことも珍しくありません。\n",
    "\n",
    "3. **Zipfの法則**: 単語の出現頻度はその順位に反比例する傾向があります（問題39で詳しく扱います）。\n",
    "\n",
    "### 結果の考察\n",
    "\n",
    "出現頻度上位の単語を見ると、日本語の文章で一般的に多用される助詞（「の」「に」「は」など）や助動詞が多く含まれています。これらは文法的な機能を担う単語であり、どのような文章でも高頻度で出現します。\n",
    "\n",
    "内容語（名詞、動詞、形容詞など）の中では、小説『吾輩は猫である』の特徴を反映した単語が上位に来ています。例えば、「猫」「主人」などの単語は、この小説の主題や登場人物に関連しています。\n",
    "\n",
    "出現頻度の分析は、テキストの特徴や主題を把握するための基本的な手法です。より詳細な分析のためには、品詞ごとの頻度分析や、複合語（連語）の頻度分析なども有効です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
