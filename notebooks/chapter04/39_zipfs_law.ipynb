{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86bff1f7",
   "metadata": {},
   "source": [
    "# 問題39: Zipfの法則\n",
    "\n",
    "単語の出現頻度順位を横軸，その出現頻度を縦軸として，両対数グラフをプロットせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題30で実装した関数を読み込む\n",
    "import sys\n",
    "sys.path.append('../..')  # 親ディレクトリをパスに追加\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 日本語表示のための設定\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "# 形態素解析結果を読み込む関数\n",
    "def load_mecab_result(file_path):\n",
    "    \"\"\"\n",
    "    MeCabの解析結果ファイルを読み込み、各形態素を辞書のリストとして返す関数\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): MeCab出力ファイルのパス\n",
    "        \n",
    "    Returns:\n",
    "        list: 文のリスト。各文は形態素（辞書）のリスト\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # EOSは文の区切り\n",
    "            if line == 'EOS\\n':\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    current_sentence = []\n",
    "                continue\n",
    "                \n",
    "            # 空行をスキップ\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "                \n",
    "            # タブで分割して表層形とそれ以外の情報に分ける\n",
    "            try:\n",
    "                surface, info = line.split('\\t')\n",
    "                \n",
    "                # カンマで分割して品詞情報などを取得\n",
    "                info_items = info.split(',')\n",
    "                \n",
    "                # 形態素情報を辞書として格納\n",
    "                morpheme = {\n",
    "                    'surface': surface,\n",
    "                    'base': info_items[6],\n",
    "                    'pos': info_items[0],\n",
    "                    'pos1': info_items[1]\n",
    "                }\n",
    "                \n",
    "                current_sentence.append(morpheme)\n",
    "            except:\n",
    "                # 不正な形式の行をスキップ\n",
    "                continue\n",
    "    \n",
    "    # 最後の文が追加されていない場合に追加\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# 単語の出現頻度を計算する関数\n",
    "def count_word_frequency(sentences):\n",
    "    \"\"\"\n",
    "    形態素解析結果から単語の出現頻度を計算する関数\n",
    "    \n",
    "    Args:\n",
    "        sentences (list): 文のリスト。各文は形態素（辞書）のリスト\n",
    "        \n",
    "    Returns:\n",
    "        Counter: 単語の出現頻度を格納したCounterオブジェクト\n",
    "    \"\"\"\n",
    "    # 全ての形態素の表層形を抽出\n",
    "    words = [morpheme['surface'] for sentence in sentences for morpheme in sentence]\n",
    "    \n",
    "    # 単語の出現回数をカウント\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    return word_counts\n",
    "\n",
    "# Zipfの法則をプロットする関数\n",
    "def plot_zipf_law(word_counts, top_n=None):\n",
    "    \"\"\"\n",
    "    単語の出現頻度順位と出現頻度の関係を両対数グラフでプロットする関数\n",
    "    \n",
    "    Args:\n",
    "        word_counts (Counter): 単語の出現頻度を格納したCounterオブジェクト\n",
    "        top_n (int): プロットする単語の数（上位n語）。Noneの場合は全単語\n",
    "    \"\"\"\n",
    "    # 出現頻度の降順でソート\n",
    "    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # 上位n語に制限（指定がある場合）\n",
    "    if top_n is not None:\n",
    "        sorted_word_counts = sorted_word_counts[:top_n]\n",
    "    \n",
    "    # 順位と頻度のリストを作成\n",
    "    ranks = list(range(1, len(sorted_word_counts) + 1))\n",
    "    frequencies = [count for word, count in sorted_word_counts]\n",
    "    \n",
    "    # データフレームに変換\n",
    "    df = pd.DataFrame({'順位': ranks, '出現頻度': frequencies})\n",
    "    \n",
    "    # 理論値の計算（Zipfの法則: f ∝ 1/r）\n",
    "    # 最も頻度の高い単語の頻度を基準に理論値を計算\n",
    "    max_freq = frequencies[0]\n",
    "    theoretical = [max_freq / r for r in ranks]\n",
    "    df['理論値'] = theoretical\n",
    "    \n",
    "    # 両対数グラフのプロット\n",
    "    plt.figure(figsize=(12, 8), dpi=300)\n",
    "    \n",
    "    # 実測値のプロット\n",
    "    plt.loglog(df['順位'], df['出現頻度'], 'o', markersize=3, alpha=0.5, label='実測値')\n",
    "    \n",
    "    # 理論値のプロット\n",
    "    plt.loglog(df['順位'], df['理論値'], 'r-', alpha=0.7, label='理論値 (Zipfの法則)')\n",
    "    \n",
    "    # グラフの装飾\n",
    "    plt.title('Zipfの法則の検証', fontsize=16)\n",
    "    plt.xlabel('出現頻度順位', fontsize=14)\n",
    "    plt.ylabel('出現頻度', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fd5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析結果の読み込み\n",
    "file_path = '../../data/neko.txt.mecab'\n",
    "sentences = load_mecab_result(file_path)\n",
    "\n",
    "# 単語の出現頻度を計算\n",
    "word_counts = count_word_frequency(sentences)\n",
    "\n",
    "# Zipfの法則をプロット（全単語）\n",
    "fig = plot_zipf_law(word_counts)\n",
    "plt.show()\n",
    "\n",
    "# Zipfの法則をプロット（上位1000語）\n",
    "fig2 = plot_zipf_law(word_counts, top_n=1000)\n",
    "plt.title('Zipfの法則の検証（上位1000語）', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 上位100語の順位と頻度を表形式で表示\n",
    "sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ranks = list(range(1, 101))\n",
    "words = [word for word, count in sorted_word_counts[:100]]\n",
    "frequencies = [count for word, count in sorted_word_counts[:100]]\n",
    "\n",
    "df = pd.DataFrame({'順位': ranks, '単語': words, '出現頻度': frequencies})\n",
    "display(df.head(20))\n",
    "\n",
    "# 理論値との比較\n",
    "max_freq = frequencies[0]\n",
    "theoretical = [max_freq / r for r in ranks]\n",
    "df['理論値'] = theoretical\n",
    "df['実測値/理論値'] = df['出現頻度'] / df['理論値']\n",
    "display(df[['順位', '単語', '出現頻度', '理論値', '実測値/理論値']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1aa24",
   "metadata": {},
   "source": [
    "## 解説\n",
    "\n",
    "この問題では、単語の出現頻度順位と出現頻度の関係を両対数グラフでプロットし、Zipfの法則を検証しました。\n",
    "\n",
    "### Zipfの法則とは\n",
    "\n",
    "Zipfの法則（ジップの法則）は、言語学者のジョージ・キングズリー・ジップによって提唱された経験則で、自然言語における単語の出現頻度に関する法則です。この法則によれば、単語の出現頻度はその出現頻度順位に反比例します。\n",
    "\n",
    "数式で表すと：\n",
    "$$f \\propto \\frac{1}{r}$$\n",
    "\n",
    "ここで、$f$は単語の出現頻度、$r$はその単語の出現頻度順位です。つまり、最も頻度の高い単語の出現頻度を$f_1$とすると、2番目に頻度の高い単語の出現頻度は約$f_1/2$、3番目は約$f_1/3$、...となります。\n",
    "\n",
    "### 実装のポイント\n",
    "\n",
    "1. **両対数グラフ**: Zipfの法則は両対数グラフ上で直線になります。これは、$\\log(f) = -\\log(r) + C$（Cは定数）という関係を示しています。\n",
    "\n",
    "2. **理論値の計算**: 最も頻度の高い単語の頻度を基準に、Zipfの法則に基づく理論値を計算しています。\n",
    "\n",
    "3. **実測値との比較**: 実測値と理論値を同じグラフ上にプロットして、Zipfの法則がどの程度成り立っているかを視覚的に確認しています。\n",
    "\n",
    "### 結果の考察\n",
    "\n",
    "グラフから、以下のような特徴が観察できます：\n",
    "\n",
    "1. **全体的な傾向**: 両対数グラフ上で、単語の出現頻度と順位の関係はおおむね直線に近い形になっています。これは、Zipfの法則が概ね成り立っていることを示しています。\n",
    "\n",
    "2. **高頻度語**: 最も頻度の高い単語（主に助詞や助動詞）は、理論値よりもやや頻度が高い傾向があります。これは、日本語の文法構造上、これらの機能語が非常に頻繁に使用されるためと考えられます。\n",
    "\n",
    "3. **中頻度語**: 中程度の頻度の単語は、理論値に比較的近い値を示しています。\n",
    "\n",
    "4. **低頻度語**: 非常に頻度の低い単語（ハプックスレゴメナなど）は、理論値からやや外れる傾向があります。これは、サンプルサイズの制約や、専門用語・固有名詞の存在などが影響していると考えられます。\n",
    "\n",
    "### Zipfの法則の意義\n",
    "\n",
    "Zipfの法則は、自然言語だけでなく、都市の人口分布、企業の規模分布、ウェブサイトのアクセス数など、様々な現象で観察されます。この普遍性は、複雑系における自己組織化や最小労力の原理などと関連していると考えられています。\n",
    "\n",
    "自然言語処理においては、Zipfの法則は語彙の分布特性を理解し、モデル化する上で重要です。例えば、低頻度語の扱い（スムージングや未知語処理）や、語彙サイズの推定などに応用されています。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
